Homework 2
================
Rachel Heise

## Problem 1

Read in the Excel sheet for Mr. Trash Wheel data and clean.

``` r
trashwheel_df = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean precipitation data for 2017 and 2018.

``` r
precip_2017_df =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
  

precip_2018_df =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
```

Combine the two precipitation data sets.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )


precip_df =
  bind_rows(precip_2017_df, precip_2018_df) %>% 
  left_join(month_df, by = "month") %>% 
  select(-month, month = "month_name") %>% 
  relocate(year, month)
```

This data comes from Mr. Trash Wheel in Baltimore, MD. The trash wheel
sits in the Inner Harbor in Baltimore and collects trash which both
cleans up the harbor and powers homes in the area. This data set is
broken down by dumpster and includes information on the specific type of
trash collected (glass bottles, grocery bags, sports balls, etc.), the
volume and weight of the trash, and how many homes were powered by the
garbage in each dumpster. The precipitation data set has data on the
total precipitation in Baltimore each month. There are 344 observations
in the final trash wheel data set, and 24 observations in the final
precipitation data set. Key variables are dumpster, homes\_powered,
weight\_tons, and total precipitation.

The total precipitation in 2018 was 70.33 and the median number of
sports balls in a dumpster in 2017 were 8.

## Problem 2

Read and clean the subway data.

``` r
nyc_subway =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  select(Line:Entry, Vending, ADA) %>% 
  mutate(Entry = recode(Entry, "YES" = TRUE, "NO" = FALSE)) %>% 
  janitor::clean_names()
```

This data set contains data on aspects of the New York City Subway
system. It includes information on subway stations and which lines and
routes they serve. This data set also contains information on aspects of
each subway station including their latitude/longitude, whether or not
they are ADA compliant, their entrance type, and whether vending is
available at the station.

To clean this data, I first selected the specific columns of interest.
Then I used the mutate function to recode the entry variable from YES/NO
to a logical vector. Finally, I used the janitor package to clean the
names of the functions.

This data has 19 columns and 1868 observations.

These data are not quite tidy yet because of the route data. Currently,
this data is organized with route information in some of 11 columns but
comparable information about each route is not necessarily found in the
same column.

``` r
distinct_subway = nyc_subway %>% 
  distinct(station_name, line, .keep_all = TRUE)

num_distinct = nrow(distinct_subway)

num_ada = 
  nrow(
    filter(distinct_subway, ada == TRUE)
  )

no_vending = nrow(filter(nyc_subway, vending == "NO"))

no_vending_entrance = nrow(filter(nyc_subway, vending == "NO", entry == TRUE))
```

There are 465 distinct stations in this data set, of which 84 are ADA
compliant.

The proportion of station entrances and exits without vending that allow
entrance is 0.3770492.

Reformat data with route number and route name as distinct variables.

``` r
nyc_subway = nyc_subway %>%
  mutate(across(route1:route11, as.character)) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name"
    ) %>% 
  drop_na(route_name)


distinct_A = nyc_subway %>% 
  filter(route_name == "A") %>% 
  distinct(station_name, line, .keep_all = TRUE)


A_ADA = distinct_A %>%
  filter(route_name == "A", ada == TRUE)
```

60 distinct stations serve the A train, and 17 of those stations are ADA
compliant.

## Problem 3

Read in pols-month csv data.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

pols_month = read_csv("./data/pols-month.csv") %>%
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "[-]", convert = TRUE) %>% 
  left_join(month_df, by = "month") %>% 
  select(-month, -day, month = "month_name") %>% 
  pivot_longer(
    cols = starts_with("prez"),
    names_to = "president") %>% 
  mutate(president = substr(president, 6, 8)) %>% 
  relocate(year, month)
```

Read in and clean snp data.

``` r
snp_df = read_csv("./data/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = "[/]", convert = TRUE) %>% 
  left_join(month_df, by = "month") %>% 
  select(-month, -day, month = "month_name") %>% 
  relocate(year, month)
```

Read in and clean unemployment data.

``` r
month_longer = 
  tibble(
    month = c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
    month_name = month.name
  )


unemployment_df = read_csv("./data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) %>% 
  left_join(month_longer, by = "month") %>% 
  select(-month, month = "month_name") %>% 
  relocate(year, month)
```

Combine the pols\_month, snp, and unemployment data sets.

``` r
pols_month = 
  left_join(pols_month, snp_df, by = c("year", "month"))

pols_month = 
  left_join(pols_month, unemployment_df, by = c("year", "month"))
```

The pols-month data set contains information about the date each piece
of data was collected, whether or not the president was republican or
democratic, and the number of republican and democratic governors,
senators, and representatives. The snp data set reports the S\&P stock
market index on each date that is recorded; this provides a high level
measure of how the stock market is performing. The final data set used
here is the unemployment data, which contains the percentage of
unemployment for each month and year. After combining these data sets,
the final data set contains 1644 observations and 12 columns. The range
of years contained in this data set is 1947 through 2015. Key variables
found in this data are close (the value of the stock market at close of
business), unemployment, and president (democrat or republican).
