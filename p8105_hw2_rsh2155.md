Homework 2
================
Rachel Heise

## Problem 1

Read in the Excel sheet for Mr. Trash Wheel data.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2017 and 2018.

``` r
precip_2017_df =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
  

precip_2018_df =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
```

Combine the two precipitation data sets.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )


precip_df =
  bind_rows(precip_2017_df, precip_2018_df) %>% 
  left_join(month_df, by = "month")
```

Data from Mr. Trash Wheel in Baltimore, MD.

What Mr. Trash Wheel does/how it operates What data is included

There are 344 rows in our final data set.

Key variables are: There is also data on monthly precipitation in
additional sheets in Excel.

``` r
summarize(filter(trashwheel_df, year == 2017), Median = median(sports_balls))
```

    ## # A tibble: 1 x 1
    ##   Median
    ##    <int>
    ## 1      8

Total precipitation in 2018: 70.33 Median number of sports balls in a
dumpster in 2017: 8

## Problem 2

``` r
nyc_subway = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  select(Line:Entry, Vending, ADA) %>% 
  mutate(Entry = recode(Entry, "YES" = TRUE, "NO" = FALSE)) %>% 
  janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This data set contains data on aspects of the New York City Subway
system. It includes information on subway stations and which lines and
routes they serve. This data set also contains information on aspects of
each subway station including their latitude/longitude, whether or not
they are ADA compliant, their entrance type, and whether vending is
available at the station.

To clean this data, I first selected the specific columns of interest.
Then I used the mutate function to recode the entry variable from YES/NO
to a logical vector. Finally, I used the janitor package to clean the
names of the functions.

This data has 19 columns and 1868 observations.

These data are not quite tidy yet because of the route data. Currently,
this data is organized with route information in some of 11 columns but
comparable information about each route is not necessarily found in the
same column.

``` r
distinct_subway = distinct(nyc_subway, station_name, route1, .keep_all = TRUE)
```

There are 450 distinct stations in this data set, of which 75 are ADA
compliant.

Reformat data with route number and route name as distinct variables.

``` r
nyc_subway = nyc_subway %>%
  mutate(across(route1:route11, as.character)) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name"
    ) %>% 
  drop_na(route_name)


distinct_A = nrow(
  distinct(
    filter(
      nyc_subway, route_name == "A"), station_name, line, .keep_all = TRUE
    )
  )


A_ADA = nrow(
  distinct(
    filter(
      nyc_subway, route_name == "A", ada == TRUE),
    station_name, line, .keep_all = TRUE
    )
  )
```

60 distinct stations serve the A train, and 17 of those stations are ADA
compliant.

## Problem 3

Read in pols-month csv data.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

pols_month = read_csv("./data/pols-month.csv") %>% 
    janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "[-]", convert = TRUE) %>% 
  left_join(month_df, by = "month") %>% 
  select(-month, -day, month = "month_name") %>% 
  pivot_longer(
    cols = starts_with("prez"),
    names_to = "president") %>% 
  mutate(president = substr(president, 6, 8)) %>% 
  relocate(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Read in and clean snp data.

``` r
snp_df = read_csv("./data/snp.csv") %>% 
    janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = "[/]", convert = TRUE) %>% 
  left_join(month_df, by = "month") %>% 
  select(-month, -day, month = "month_name") %>% 
  relocate(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Read in and clean unemployment data.

``` r
month_longer = 
  tibble(
    month = c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
    month_name = month.name
  )


unemployment_df = read_csv("./data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) %>% 
  left_join(month_longer, by = "month") %>% 
  select(-month, month = "month_name") %>% 
  relocate(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Combine the data sets.

``` r
pols_month = 
  left_join(pols_month, snp_df, by = c("year", "month"))

pols_month = 
  left_join(pols_month, unemployment_df, by = c("year", "month"))
```

The pols-month data set contains information about the date each piece
of data was collected, whether or not the president was republican or
democratic, the number of republican and democratic governors, senators,
and representatives. The snp data set reports the S\&P stock market
index on each date that is recorded; this provides a high level measure
of how the stock market is performing. The final data set used here was
the unemployment data, which contained the percentage of unemployment
for each month and year. After combining these data sets, the final data
set contains 1644 observations and 12 columns. The range of years
contained in this data set is 1947 through 2015. Key variables found in
this data are close (the value of the stock market at close of
business), unemployment, and president (democrat or republican).
